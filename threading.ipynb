{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "recipe_url_list = []\n",
    "with open(\"output/recipe_url_list.csv\",\"r\",encoding=\"utf-8\") as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        recipe_url_list.append((row[0],row[1]))\n",
    "# recipe_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(recipe_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcats = []\n",
    "for subcat in recipe_url_list:\n",
    "    subcats.append(subcat[0])\n",
    "subcat_filter = set(subcats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為了保持順序性做的處理\n",
    "subcat_set = []\n",
    "for subcat in subcats:\n",
    "    if subcat in subcat_filter:\n",
    "        if subcat_set.count(subcat) == 0:\n",
    "            subcat_set.append(subcat)\n",
    "# len(subcat_set)\n",
    "# subcat_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(0, len(subcat_set), 10)\n",
    "groups = []\n",
    "for g in r:\n",
    "    groups.append(g)\n",
    "groups[-1] = len(subcat_set)\n",
    "# groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "devided_subcat_filter = []\n",
    "for i in range(len(groups)-1):\n",
    "    devided_subcat_filter.append(subcat_set[groups[i]:groups[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "# for dsf in devided_subcat_filter:\n",
    "#     print(dsf)\n",
    "# len(devided_subcat_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先把所有的 recipe 塞進一個 queue\n",
    "import queue\n",
    "recipe_queue = queue.Queue()\n",
    "for recipe in recipe_url_list:\n",
    "    recipe_queue.put(recipe)\n",
    "# recipe_queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "塞完了\n"
     ]
    }
   ],
   "source": [
    "# 產生 Queue 的 list\n",
    "divided_recipe_url_list = []\n",
    "\n",
    "tmp = None # 暫存用來當分界點比對的那份食譜\n",
    "for dsf in devided_subcat_filter:\n",
    "#     print(dsf)\n",
    "    ten_subcats_recipes = []\n",
    "    while recipe_queue.qsize() > 0:\n",
    "        recipe = recipe_queue.get()\n",
    "        if recipe[0] in dsf:\n",
    "            if tmp is not None:\n",
    "                ten_subcats_recipes.append(tmp) # 把分界點的那份食譜放進去 -> 該分類食譜list的第一個元素\n",
    "                tmp = None\n",
    "            ten_subcats_recipes.append(recipe)\n",
    "        else:\n",
    "            tmp = recipe\n",
    "            divided_recipe_url_list.append(ten_subcats_recipes)\n",
    "            break\n",
    "    # 最後一個分類食譜的list\n",
    "    if recipe_queue.qsize() == 0:\n",
    "        divided_recipe_url_list.append(ten_subcats_recipes)\n",
    "        print(\"塞完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每十個分類的食譜塞進一個Queue\n",
    "import queue\n",
    "queue_list = []\n",
    "for drul in divided_recipe_url_list:\n",
    "    recipe_queue = queue.Queue()\n",
    "    for each_recipe in drul:\n",
    "        recipe_queue.put(each_recipe)\n",
    "    queue_list.append(recipe_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 測試\n",
    "# print(len(divided_recipe_url_list))\n",
    "# sum = 0\n",
    "# for dsf in divided_recipe_url_list:\n",
    "#     sum += len(dsf)\n",
    "# print(sum)\n",
    "# # divided_recipe_url_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 測試 \n",
    "# print(len(queue_list))\n",
    "# sum = 0\n",
    "# for q in queue_list:\n",
    "#     sum += q.qsize()\n",
    "# print(sum)\n",
    "# queue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要把食物分類塞到不同的Queue，這樣執行緒才會快 \n",
    "# 已改寫下面的邏輯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的Try-catch架構\n",
    "# Try-catch的完整結構應該是這樣：try, except, else, finally\n",
    "# try：需要被監控是否會出錯的程式區塊\n",
    "# except：出了哪種錯誤，要有怎樣相對應的處理\n",
    "# else：都沒錯誤，就會執行此區塊的程式\n",
    "# finally：不論如何都會執行此區塊的程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** python 3.6 版本以上，dict 會記住元素的插入順序，大部分情況下不再需要使用OrderedDict ***\n",
    "import sys\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "\n",
    "# 進入每個食譜\n",
    "def getRecipeJson(recipe_to_crawl):\n",
    "    \n",
    "    headers = {\"user-agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\"\n",
    "              }\n",
    "    \n",
    "    try:\n",
    "        recipe_html = BeautifulSoup(requests.get(recipe_to_crawl[1], headers=headers).text)\n",
    "#         print(\"get html successfully\")\n",
    "    except:\n",
    "        # sys.exc_info()[0] 就是用來取出except的錯誤訊息的方法\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        print(\"failed to download %s\" %(str(recipe_to_crawl)))\n",
    "        \n",
    "        return recipe_to_crawl\n",
    "    \n",
    "    else:\n",
    "        # 檢查是否被伺服器ban了\n",
    "        if recipe_html.find('h1') is not None:\n",
    "            # 取得食譜名、食譜圖片網址、材料清單\n",
    "            # recipe_name : str\n",
    "            recipe_name = recipe_html.find(\"h1\").text.strip()\n",
    "\n",
    "            # img_src : str\n",
    "            recipe_img_src = recipe_html.find(\"img\", class_=\"main-pic\")[\"src\"]\n",
    "\n",
    "            # ingredients : dict\n",
    "            ingredients = recipe_html.find_all(\"div\", itemprop=\"ingredients\")\n",
    "            ingredient_preparation = {}\n",
    "            for ingre in ingredients:\n",
    "                ingre_name = ingre.find(\"div\", class_=\"ingredient-name\").text\n",
    "                ingre_unit = ingre.find(\"div\", class_=\"ingredient-unit\").text\n",
    "                ingredient_preparation[ingre_name] = ingre_unit\n",
    "\n",
    "            # recipe_catergory : str \n",
    "            recipe_category = recipe_to_crawl[0]\n",
    "\n",
    "            #  做成一個 Recipe 物件{}\n",
    "            a_recipe = {}\n",
    "            a_recipe[\"食譜名稱\"] = recipe_name\n",
    "            a_recipe[\"料理圖片\"] = recipe_img_src\n",
    "            a_recipe[\"材料\"] = ingredient_preparation\n",
    "            a_recipe[\"食譜網址\"] = recipe_to_crawl[1]\n",
    "            a_recipe[\"食譜分類\"] = recipe_category\n",
    "\n",
    "            return a_recipe\n",
    "        \n",
    "        else:            \n",
    "            print(recipe_html.getText()) # surver replies : Retry later\n",
    "            random_int = randint(1,10)\n",
    "            print(\"let's take a break for %s seconds\" % (random_int))\n",
    "            time.sleep(random_int)\n",
    "            \n",
    "            return recipe_to_crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from random import randint\n",
    "\n",
    "class Worker(threading.Thread):\n",
    "    def __init__(self, queue, worker_num, qnum, lock, error_writer_lock):\n",
    "        # 繼承父類別的方法 兩種寫法\n",
    "        threading.Thread.__init__(self)\n",
    "        # super(Worker,self).__init__()\n",
    "        \n",
    "        self.queue = queue\n",
    "        self.num = worker_num\n",
    "        self.qnum = qnum\n",
    "        self.lock = lock\n",
    "        self.error_writer_lock = error_writer_lock\n",
    "\n",
    "    def run(self):\n",
    "        while self.queue.qsize() > 0:\n",
    "            \n",
    "            recipe_to_crawl = self.queue.get()\n",
    "            recipe_subcat_name = recipe_to_crawl[0]\n",
    "            \n",
    "            a_recipe = getRecipeJson(recipe_to_crawl)\n",
    "            \n",
    "            if type(a_recipe) is dict:\n",
    "                # 取得 lock\n",
    "                self.lock.acquire()\n",
    "#                 print(\"Lock acquired by Worker %d\" % self.num)\n",
    "\n",
    "                try:\n",
    "                    # 不能讓多個執行緒同時進行的工作\n",
    "                    # 存進 recipes.json\n",
    "                    with open(\"recipe_json_output/recipes_%s.json\" %(recipe_subcat_name), \"a\", encoding=\"utf-8\") as txt_outfile:\n",
    "                        txt_outfile.write(repr(a_recipe) + \",\")\n",
    "#                     print(\"Worker %d of queue %s saved the recipe of %s to recipes_%s.json\" % (self.num, self.qnum, a_recipe[\"食譜名稱\"], recipe_subcat_name))\n",
    "                    if self.queue.qsize != 0:\n",
    "                        pass\n",
    "#                         print(\"There are now %d recipes to retrieve in queue %d \" % (self.queue.qsize(),self.qnum))\n",
    "                    else:\n",
    "                        print(\"The queue %d is empty\" %(self.qnum))\n",
    "                except IOError as e:\n",
    "                    print(e.args[0],e.args[1])\n",
    "                    print(\"%s的食譜沒有存進去\" %(a_recipe[\"食譜名稱\"]))\n",
    "                finally:\n",
    "                    # 釋放 lock\n",
    "                    self.lock.release()\n",
    "                    time.sleep(randint(1,10))\n",
    "#                     print(\"Lock released by Worker %d\" % self.num)\n",
    "            elif type(a_recipe) is tuple:\n",
    "                # 把沒抓成功的食譜存起來\n",
    "                self.error_writer_lock.acquire()\n",
    "                with open(\"recipes_crawl_failure.json\", \"a\", encoding=\"utf-8\") as failFile:\n",
    "                    a_recipe_str = repr(recipe_to_crawl)\n",
    "                    failFile.write(a_recipe_str + \",\")\n",
    "                self.error_writer_lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、執行緒共享建立它的程序的地址空間,程序有自己的地址空間\n",
    "\n",
    "# 2、執行緒可以訪問程序所有的資料，執行緒可以相互訪問\n",
    "\n",
    "# 3、執行緒之間的資料是獨立的\n",
    "\n",
    "# 4、子程序複製執行緒的資料\n",
    "\n",
    "# 5、子程序啟動後是獨立的 ，父程序只能殺掉子程序，而不能進行資料交換\n",
    "\n",
    "# 6、修改執行緒中的資料，都是會影響其他的執行緒，而對於程序的更改，不會影響子程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker  0 of queue num 1 created\n",
      "worker  1 of queue num 1 created\n",
      "worker  2 of queue num 1 created\n",
      "worker  0 of queue num 2 created\n",
      "worker  1 of queue num 2 created\n",
      "worker  2 of queue num 2 created\n",
      "worker  0 of queue num 3 created\n",
      "worker  1 of queue num 3 created\n",
      "worker  2 of queue num 3 created\n",
      "worker  0 of queue num 4 created\n",
      "worker  1 of queue num 4 created\n",
      "worker  2 of queue num 4 created\n",
      "worker  0 of queue num 5 created\n",
      "worker  1 of queue num 5 created\n",
      "worker  2 of queue num 5 created\n",
      "worker  0 of queue num 6 created\n",
      "worker  1 of queue num 6 created\n",
      "worker  2 of queue num 6 created\n",
      "worker  0 of queue num 7 created\n",
      "worker  1 of queue num 7 created\n",
      "worker  2 of queue num 7 created\n",
      "worker  0 of queue num 8 created\n",
      "worker  1 of queue num 8 created\n",
      "worker  2 of queue num 8 created\n",
      "worker  0 of queue num 9 created\n",
      "worker  1 of queue num 9 created\n",
      "worker  2 of queue num 9 created\n",
      "worker  0 of queue num 10 created\n",
      "worker  1 of queue num 10 created\n",
      "worker  2 of queue num 10 created\n",
      "worker  0 of queue num 11 created\n",
      "worker  1 of queue num 11 created\n",
      "worker  2 of queue num 11 created\n",
      "worker  0 of queue num 12 created\n",
      "worker  1 of queue num 12 created\n",
      "worker  2 of queue num 12 created\n",
      "worker  0 of queue num 13 created\n",
      "worker  1 of queue num 13 created\n",
      "worker  2 of queue num 13 created\n",
      "worker  0 of queue num 14 created\n",
      "worker  1 of queue num 14 created\n",
      "worker  2 of queue num 14 created\n",
      "worker  0 of queue num 15 created\n",
      "worker  1 of queue num 15 created\n",
      "worker  2 of queue num 15 created\n",
      "worker  0 of queue num 16 created\n",
      "worker  1 of queue num 16 created\n",
      "worker  2 of queue num 16 created\n",
      "worker  0 of queue num 17 created\n",
      "worker  1 of queue num 17 created\n",
      "worker  2 of queue num 17 created\n",
      "worker  0 of queue num 18 created\n",
      "worker  1 of queue num 18 created\n",
      "worker  2 of queue num 18 created\n",
      "worker  0 of queue num 19 created\n",
      "worker  1 of queue num 19 created\n",
      "worker  2 of queue num 19 created\n",
      "I am the main thread, I am waiting for the threads finishing their jobs\n",
      "Retry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 7 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 1 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 5 seconds\n",
      "Retry later\n",
      "Retry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "\n",
      "let's take a break for 9 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 5 secondsRetry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 10 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 3 secondsRetry later\n",
      "\n",
      "let's take a break for 5 seconds\n",
      "\n",
      "\n",
      "Retry later\n",
      "\n",
      "let's take a break for 10 seconds\n",
      "\n",
      "let's take a break for 5 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 2 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 1 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 2 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 9 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 7 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 5 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 4 seconds\n",
      "\n",
      "let's take a break for 4 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 1 seconds\n",
      "\n",
      "let's take a break for 8 seconds\n",
      "Retry later\n",
      "Retry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "\n",
      "let's take a break for 1 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 7 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 7 seconds\n",
      "\n",
      "let's take a break for 2 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 10 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 8 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 9 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 2 seconds\n",
      "Retry later\n",
      "\n",
      "Retry later\n",
      "\n",
      "let's take a break for 2 seconds\n",
      "let's take a break for 6 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 3 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 5 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 2 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 1 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 3 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 8 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 8 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 6 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 10 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 8 seconds\n",
      "Retry later\n",
      "\n",
      "let's take a break for 9 seconds\n",
      "\n",
      "let's take a break for 3 seconds\n",
      "Done.\n",
      "startToCrawl's time consumed(h) is: 4.229575403067801\n"
     ]
    }
   ],
   "source": [
    "# 主程式區\n",
    "from bs4 import BeautifulSoup\n",
    "from tools.countTimeDecorator import countTimeDecorator\n",
    "import csv\n",
    "import time\n",
    "import queue\n",
    "import requests\n",
    "import threading\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 建立 lock\n",
    "# 檔案IO 安全保護鎖\n",
    "# lock = threading.Lock()\n",
    "# print(lock)\n",
    "error_writer_lock = threading.Lock()\n",
    "\n",
    "@countTimeDecorator(time_unit=\"h\")\n",
    "def startToCrawl():\n",
    "    \n",
    "    qnum = 0\n",
    "    lock_list = []\n",
    "    worker_threads_list = []\n",
    "    for ten_subcat_queue in queue_list:\n",
    "        qnum += 1\n",
    "        lock = threading.Lock()\n",
    "        lock_list.append(lock)\n",
    "        num_worker_threads = 3\n",
    "        threads = []\n",
    "        for worker_num in range(num_worker_threads):\n",
    "            t = Worker(ten_subcat_queue, worker_num, qnum, lock, error_writer_lock)\n",
    "            print(\"worker \", str(worker_num), \"of queue num\", str(qnum), \"created\")\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "            time.sleep(1)\n",
    "\n",
    "        worker_threads_list.append(threads)\n",
    "\n",
    "    worker_list = []\n",
    "    for worker_threads in worker_threads_list:\n",
    "        for worker_thread in worker_threads:\n",
    "            worker_list.append(worker_thread)\n",
    "\n",
    "\n",
    "    print(\"I am the main thread, I am waiting for the threads finishing their jobs\")\n",
    "    for worker in worker_list:\n",
    "        worker.join()\n",
    "\n",
    "    # with open(\"recipes.json\", \"r\", encoding=\"utf-8\") as jsonFile:\n",
    "    #     dict_strs = jsonFile.read()\n",
    "    #     recipes = list(eval(dict_strs))\n",
    "\n",
    "    # with open(\"clean_recipes.json\", \"w\", encoding=\"utf-8\") as jsonFile:\n",
    "    #     json_str = repr(recipes)\n",
    "    #     jsonFile.write(json_str)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    startToCrawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/even/PycharmProjects/recipeCrawler\n",
      "/Users/even/PycharmProjects/recipeCrawler/recipe_json_output\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 把每一份json檔讀進來清理\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "print(pwd)\n",
    "data_dir = os.path.join(pwd, \"recipe_json_output\")\n",
    "print(data_dir)\n",
    "recipe_json_list = os.listdir(data_dir)\n",
    "print(recipe_json_list)\n",
    "\n",
    "for recipe_json in recipe_json_list:\n",
    "    infile = \"recipe_json_output/\" + recipe_json\n",
    "    if os.path.isfile(infile):\n",
    "        with open(infile, \"r\", encoding=\"utf-8\") as jsonFile:\n",
    "            dict_strs = jsonFile.read()\n",
    "            recipes = list(eval(dict_strs))\n",
    "\n",
    "        outfile = \"clean_recipe_json_output/\" + recipe_json\n",
    "        with open(outfile, \"w\", encoding=\"utf-8\") as jsonFile:\n",
    "            json_str = repr(recipes)\n",
    "            jsonFile.write(json_str)\n",
    "        \n",
    "# result = [f for f in os.listdir(dirPath) if os.path.isfile(os.path.join(dirPath, f))]\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
